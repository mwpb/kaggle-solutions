{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Build a sentiment analysis / polarity model\n",
    "\n",
    "Sentiment analysis can be casted as a binary text classification problem,\n",
    "that is fitting a linear classifier on features extracted from the text\n",
    "of the user messages so as to guess whether the opinion of the author is\n",
    "positive or negative.\n",
    "\n",
    "In this examples we will use a movie review dataset.\n",
    "\n",
    "\"\"\"\n",
    "# Author: Olivier Grisel <olivier.grisel@ensta.org>\n",
    "# License: Simplified BSD\n",
    "\n",
    "import sys, os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the training data folder must be passed as first argument\n",
    "# directory = directory = os.path.dirname(os.path.realpath(__file__))\n",
    "movie_reviews_data_folder = \"../data/movie_reviews/txt_sentoken/\"\n",
    "dataset = load_files(movie_reviews_data_folder, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split the dataset in training and test set:\n",
    "docs_train, docs_test, y_train, y_test = train_test_split(\n",
    "dataset.data, dataset.target, test_size=0.25, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TASK: Build a vectorizer / classifier pipeline that filters out tokens\n",
    "# # that are too rare or too frequent\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df = 0.8, min_df = 0.2)\n",
    "classifier = LinearSVC()\n",
    "pipeline = Pipeline([\n",
    "    ('vect', vectorizer),\n",
    "    ('class', classifier)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class__C': 0.1, 'vect__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "pg = {\n",
    "    'vect__ngram_range': [(1, 1), (2, 2)], # best: (1, 1) , (1, 2) is better than both\n",
    "    'class__C': [1e-4, 1e-3, 1e-2, 1e-1, 1] # best: 0.1\n",
    "}\n",
    "\n",
    "# # TASK: print the cross-validated scores for the each parameters set\n",
    "# # explored by the grid search\n",
    "\n",
    "gs = GridSearchCV(pipeline, cv = 3, param_grid = pg, n_jobs = -1)\n",
    "gs.fit(docs_train, y_train)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.76      0.77      0.77       260\n",
      "         pos       0.75      0.74      0.75       240\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       500\n",
      "   macro avg       0.76      0.76      0.76       500\n",
      "weighted avg       0.76      0.76      0.76       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # TASK: Predict the outcome on the testing set and store it in a variable\n",
    "# # named y_predicted\n",
    "\n",
    "y_predicted = gs.predict(docs_test)\n",
    "\n",
    "# # Print the classification report\n",
    "print(metrics.classification_report(\n",
    "    y_test, y_predicted, \n",
    "    target_names=dataset.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[201  59]\n",
      " [ 62 178]]\n"
     ]
    }
   ],
   "source": [
    "# # Print and plot the confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, y_predicted)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.matshow(cm)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
